---
layout: default
---

# Codes

[Training in Transformer Architecture](./pages/train_transformer.md)

[Generative Pre-trained Transformer (GPT)](./pages/gpt.md)

[Recommender System](./pages/recommedner_system.md)

# Transformer

![Transformer](https://www.tensorflow.org/images/tutorials/transformer/transformer.png)


# Labor Information

## Requirements

- Fewer absences than allowed. Active participation in classes.
- Organizing into teams (4 people).
- Creating a working application and presenting it in the form of a video using the solutions and models learned in class.
     - It must be uploaded to Github and shared.
     - Maximum length of video is 5-10 minutes.
     - In the video, each creator must present their own contribution. (for 3-8 minutes)
     - At the end of the video, the application must be shown in action. (for 1-2 minutes)
- The team members do not receive a uniform ticket, but get the ticket in proportion to the task they have completed in the project.
- Method of submission: [By email](mailto:lakatos.robert@inf.unideb.hu)
- Submission deadline: 07.12.2023

## Description

Within the framework of the subject, students will learn about the basics of natural language text processing (NLP). In addition, they also gain practical experience while solving various tasks. Main topics: logistic regression, naive Bayes model, PCA, n-gram models, Word2Vec, classical and recurrent neural networks. Furthermore, during the completion of the subject, students can gain insight into current, modern neural architectures. During the semester, students will also have the opportunity to test and train these architectures on real data using cloud-based services (Google Collab).

<!-- ## Competencies

Upon successful completion of the subject, students will be able to implement various NLP architectures in real environments. In addition, they can acquire the knowledge necessary to successfully complete the first two courses of deeplarning.ai's Natural Language Processing Specialization, as well as get closer to obtaining the Microsoft "Exam AI-900: Microsoft Azure AI Fundamentals" certificate. -->

## Usefull Links

- ![Huggingface](https://huggingface.co/)
- ![Keras](https://keras.io/)
- ![Tensorflow](https://www.tensorflow.org/)
- ![Pytorch](https://pytorch.org/)
- ![Pyton](https://www.python.org/)
- ![Google Colab][https://colab.google/]

## Recommended Literatures

1. [Jurafsky, Daniel, and James H. Martin. "Speech and language processing (draft)." Chapter A: Hidden Markov Models (Draft of September 11, 2018). Retrieved March 19 (2018): 2019.](https://ms.b-ok.xyz/book/3560643/4a6ab2)
2. [Eisenstein, Jacob. "Introduction to natural language processing." MIT press, 2019.](https://mitpress.mit.edu/9780262042840/introduction-to-natural-language-processing/)
3. [Goldberg, Yoav. "A primer on neural network models for natural language processing." Journal of Artificial Intelligence Research 57 (2016): 345-420.](https://arxiv.org/pdf/1510.00726.pdf)
4. [Francois Chollet. "Deep Learning with Python"](https://www.amazon.com/Deep-Learning-Python-Francois-Chollet/dp/1617294438)
5. [Hugging Face NLP Course](https://huggingface.co/learn/nlp-course/chapter0/1?fw=pt)

# Usefull Publications

[1] ![Attention Is All You Need](https://arxiv.org/pdf/1706.03762.pdf)

[2] ![Improving Language Understanding by Generative Pre-Training](https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf)

# Kapcsolat

- Lakatos RÃ³bert
- `lakatos.robert@inf.unideb.hu`